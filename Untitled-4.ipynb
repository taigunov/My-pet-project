{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtaig\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 69443904.0000 - mae: 8265.3232 - val_loss: 69016776.0000 - val_mae: 8229.3555\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69085600.0000 - mae: 8244.0459 - val_loss: 69007840.0000 - val_mae: 8228.8213\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69563720.0000 - mae: 8269.9473 - val_loss: 68997128.0000 - val_mae: 8228.1807\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 70396752.0000 - mae: 8319.3213 - val_loss: 68983952.0000 - val_mae: 8227.3936\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 70080624.0000 - mae: 8301.7275 - val_loss: 68967208.0000 - val_mae: 8226.3916\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 70591560.0000 - mae: 8338.1367 - val_loss: 68945920.0000 - val_mae: 8225.1162\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 70318016.0000 - mae: 8318.1064 - val_loss: 68919768.0000 - val_mae: 8223.5518\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 69756968.0000 - mae: 8276.3701 - val_loss: 68887192.0000 - val_mae: 8221.6045\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 69651456.0000 - mae: 8280.2559 - val_loss: 68847088.0000 - val_mae: 8219.2041\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 71426464.0000 - mae: 8388.2324 - val_loss: 68798032.0000 - val_mae: 8216.2725\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 70011792.0000 - mae: 8295.2061 - val_loss: 68739696.0000 - val_mae: 8212.7822\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 70580888.0000 - mae: 8327.3057 - val_loss: 68670640.0000 - val_mae: 8208.6426\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69992064.0000 - mae: 8296.0742 - val_loss: 68589360.0000 - val_mae: 8203.7656\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 71206184.0000 - mae: 8374.5361 - val_loss: 68494088.0000 - val_mae: 8198.0508\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 70366840.0000 - mae: 8317.7568 - val_loss: 68383944.0000 - val_mae: 8191.4448\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69657384.0000 - mae: 8276.0391 - val_loss: 68258936.0000 - val_mae: 8183.9355\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69143024.0000 - mae: 8240.4717 - val_loss: 68116560.0000 - val_mae: 8175.3584\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 70296368.0000 - mae: 8320.9570 - val_loss: 67954768.0000 - val_mae: 8165.6206\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 68521872.0000 - mae: 8200.8613 - val_loss: 67772840.0000 - val_mae: 8154.6665\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 68686528.0000 - mae: 8210.5820 - val_loss: 67570080.0000 - val_mae: 8142.4165\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69504872.0000 - mae: 8267.0527 - val_loss: 67343016.0000 - val_mae: 8128.6963\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69072464.0000 - mae: 8245.7949 - val_loss: 67092984.0000 - val_mae: 8113.5396\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 68171720.0000 - mae: 8183.4609 - val_loss: 66818184.0000 - val_mae: 8096.8623\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 68390080.0000 - mae: 8204.1289 - val_loss: 66517700.0000 - val_mae: 8078.5874\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 67318416.0000 - mae: 8141.8662 - val_loss: 66191084.0000 - val_mae: 8058.6743\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 66638516.0000 - mae: 8097.1587 - val_loss: 65837200.0000 - val_mae: 8037.0356\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 66226340.0000 - mae: 8067.8271 - val_loss: 65451708.0000 - val_mae: 8013.4136\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 67508600.0000 - mae: 8137.6797 - val_loss: 65037704.0000 - val_mae: 7987.9673\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 65737148.0000 - mae: 8042.4673 - val_loss: 64599448.0000 - val_mae: 7960.8384\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 64631084.0000 - mae: 7970.8911 - val_loss: 64128880.0000 - val_mae: 7931.6167\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 65780092.0000 - mae: 8043.4819 - val_loss: 63626256.0000 - val_mae: 7900.2769\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 65270448.0000 - mae: 8006.7671 - val_loss: 63094396.0000 - val_mae: 7866.9370\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 64212360.0000 - mae: 7942.9814 - val_loss: 62526928.0000 - val_mae: 7831.2012\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 62202988.0000 - mae: 7811.8105 - val_loss: 61930460.0000 - val_mae: 7793.3896\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 62888140.0000 - mae: 7853.0698 - val_loss: 61298116.0000 - val_mae: 7753.1738\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 62292932.0000 - mae: 7823.8218 - val_loss: 60633684.0000 - val_mae: 7710.5801\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 62357368.0000 - mae: 7832.1353 - val_loss: 59933876.0000 - val_mae: 7665.5439\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 60549336.0000 - mae: 7716.1626 - val_loss: 59203636.0000 - val_mae: 7618.1035\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 59967184.0000 - mae: 7671.6362 - val_loss: 58440496.0000 - val_mae: 7568.2554\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 60322108.0000 - mae: 7705.8325 - val_loss: 57637776.0000 - val_mae: 7515.4399\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 58231376.0000 - mae: 7556.6094 - val_loss: 56810888.0000 - val_mae: 7460.4536\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 57653892.0000 - mae: 7521.9814 - val_loss: 55954868.0000 - val_mae: 7403.0791\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 57321692.0000 - mae: 7492.1582 - val_loss: 55058524.0000 - val_mae: 7342.5283\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55368508.0000 - mae: 7371.4941 - val_loss: 54144964.0000 - val_mae: 7280.0688\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54650552.0000 - mae: 7318.9790 - val_loss: 53210616.0000 - val_mae: 7215.5635\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52625124.0000 - mae: 7176.5400 - val_loss: 52247380.0000 - val_mae: 7148.2725\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 52853516.0000 - mae: 7188.0479 - val_loss: 51252232.0000 - val_mae: 7078.0303\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52741660.0000 - mae: 7184.7490 - val_loss: 50228868.0000 - val_mae: 7005.0669\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 50744232.0000 - mae: 7042.5200 - val_loss: 49184464.0000 - val_mae: 6929.5781\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 49362192.0000 - mae: 6946.2676 - val_loss: 48119204.0000 - val_mae: 6851.4595\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45457780.0000 - mae: 6627.6294\n",
      "Test Loss: 45834360.0, Test MAE: 6654.693359375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "[[1221.8253 ]\n",
      " [ 911.30225]\n",
      " [1484.1718 ]\n",
      " [ 847.1021 ]\n",
      " [ 898.3121 ]\n",
      " [1665.4188 ]\n",
      " [2639.672  ]\n",
      " [1254.9531 ]\n",
      " [ 856.5529 ]\n",
      " [ 905.43677]\n",
      " [1221.5532 ]\n",
      " [ 797.29205]\n",
      " [ 903.09845]\n",
      " [1010.64154]\n",
      " [1029.9629 ]\n",
      " [1516.5675 ]\n",
      " [ 781.4804 ]\n",
      " [1443.743  ]\n",
      " [ 917.9986 ]\n",
      " [1379.6532 ]\n",
      " [ 940.6016 ]\n",
      " [ 990.99445]\n",
      " [2292.064  ]\n",
      " [ 996.868  ]\n",
      " [2219.2654 ]\n",
      " [1060.7291 ]\n",
      " [ 843.1333 ]\n",
      " [ 923.0828 ]\n",
      " [1364.7059 ]\n",
      " [ 832.4323 ]\n",
      " [1259.2378 ]\n",
      " [1254.4215 ]\n",
      " [1658.2577 ]\n",
      " [ 998.1993 ]\n",
      " [ 814.93634]\n",
      " [1147.789  ]\n",
      " [ 929.8317 ]\n",
      " [ 956.56995]\n",
      " [1184.1919 ]\n",
      " [ 902.1285 ]\n",
      " [1137.7203 ]\n",
      " [ 929.0373 ]\n",
      " [1581.8595 ]\n",
      " [1623.9546 ]\n",
      " [1037.4554 ]\n",
      " [1193.0311 ]\n",
      " [ 992.20526]\n",
      " [1156.3734 ]\n",
      " [1418.3842 ]\n",
      " [1291.8821 ]\n",
      " [1370.3324 ]\n",
      " [1493.9099 ]\n",
      " [ 903.3262 ]\n",
      " [1443.6731 ]\n",
      " [2502.119  ]\n",
      " [ 911.00214]\n",
      " [1202.5629 ]\n",
      " [1915.9359 ]\n",
      " [1046.8916 ]\n",
      " [2862.6628 ]\n",
      " [2032.2821 ]\n",
      " [ 933.1181 ]\n",
      " [1795.3995 ]\n",
      " [2346.7742 ]\n",
      " [ 948.6925 ]\n",
      " [1318.5422 ]\n",
      " [1123.3446 ]\n",
      " [1302.1425 ]\n",
      " [1749.4264 ]\n",
      " [1659.462  ]\n",
      " [1696.0216 ]\n",
      " [1851.1666 ]\n",
      " [1076.7341 ]\n",
      " [ 882.6878 ]\n",
      " [1035.9667 ]\n",
      " [2655.05   ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загрузка данных из Excel файла\n",
    "data = pd.read_excel('C:/Users/mtaig/Desktop/ds_lact_2.xlsx')\n",
    "\n",
    "# Предположим, что целевая переменная - это 'Milk yield 305, kg - 1 Lac.'\n",
    "# и остальные столбцы - это признаки\n",
    "X = data.drop(columns=['Milk yield 305, kg - 1 Lac.'])\n",
    "y = data['Milk yield 305, kg - 1 Lac.']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Создание модели\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}')\n",
    "\n",
    "# Прогнозирование на новых данных\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
